ðŸ“˜ Cell 1 â€“ Imports
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score

from training.feature_engineering import FeatureEngineer

ðŸ“˜ Cell 2 â€“ Load Dataset
df = pd.read_csv("../data/training_dataset.csv")
df.head()

ðŸ“˜ Cell 3 â€“ Feature Engineering
df = FeatureEngineer.preprocess(df)
X, y = FeatureEngineer.select_features(df)

X.head()

ðŸ“˜ Cell 4 â€“ Train Model
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model = RandomForestRegressor(n_estimators=100, max_depth=5)
model.fit(X_train, y_train)

ðŸ“˜ Cell 5 â€“ Evaluation
predictions = model.predict(X_test)

mae = mean_absolute_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

print("MAE:", round(mae, 4))
print("R2:", round(r2, 4))

ðŸ“˜ Cell 6 â€“ Feature Importance
importances = model.feature_importances_

feature_names = X.columns

plt.figure()
plt.bar(feature_names, importances)
plt.title("Feature Importance")
plt.xticks(rotation=45)
plt.show()
